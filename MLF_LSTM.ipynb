{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1850624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:24:41.846222: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 17:24:41.846354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 17:24:41.867938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 17:24:41.925595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 17:24:43.364409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/apps/cent7/jupyterhub/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Dropout, Flatten, concatenate, Input, LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746f42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/depot/lanhamm/project-smith/Test/sales1CA2_Melt_Calendar_OutTreat_LabelEnc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ea6e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'wday', 'month', 'year', 'item_id_enc', 'dept_id_enc',\n",
       "       'store_id_enc', 'event_name_1_enc', 'event_type_1_enc',\n",
       "       'event_name_1_enc.1', 'snap_CA', 'sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19815e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "sequence_length = 31\n",
    "sequences = []\n",
    "categorical_data = []\n",
    "numerical_data = []\n",
    "targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebd8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data is sorted if it's not already\n",
    "df.sort_values(by=['day', 'year', 'month', 'wday', 'store_id_enc', 'dept_id_enc', 'item_id_enc', 'event_type_1_enc', 'event_name_1_enc', 'snap_CA'], inplace=True)\n",
    "\n",
    "# Group by the categorical variables\n",
    "grouped = df.groupby(['store_id_enc', 'dept_id_enc', 'item_id_enc', 'event_type_1_enc', 'event_name_1_enc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec42d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, group in grouped:\n",
    "    sales = group['sales'].values\n",
    "    \n",
    "    # Convert necessary columns to numpy arrays\n",
    "    store_ids = group['store_id_enc'].values\n",
    "    dept_ids = group['dept_id_enc'].values\n",
    "    item_ids = group['item_id_enc'].values\n",
    "    events = group['event_name_1_enc'].values\n",
    "    evtype = group['event_type_1_enc'].values\n",
    "    \n",
    "    # New: Numerical features\n",
    "    days = group['day'].values\n",
    "    years = group['year'].values\n",
    "    months = group['month'].values\n",
    "    wd = group['wday'].values\n",
    "    snap_CA = group['snap_CA'].values\n",
    "    \n",
    "    for i in range(len(sales) - sequence_length):\n",
    "        sequences.append(sales[i:i+sequence_length])\n",
    "        targets.append(sales[i+sequence_length])\n",
    "        categorical_data.append([store_ids[i], dept_ids[i], item_ids[i], events[i], evtype[i]])\n",
    "        # Include numerical features\n",
    "        numerical_data.append([days[i], years[i], months[i], wd[i], snap_CA[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22766ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "sequences = np.array(sequences)\n",
    "targets = np.array(targets)\n",
    "categorical_data = np.array(categorical_data)\n",
    "numerical_data = np.array(numerical_data)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_sequences, X_test_sequences, y_train, y_test, X_train_categorical, X_test_categorical, X_train_numerical, X_test_numerical = train_test_split(sequences, targets, categorical_data, numerical_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21eddac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input for LSTM\n",
    "X_train_sequences = X_train_sequences.reshape((X_train_sequences.shape[0], X_train_sequences.shape[1], 1))\n",
    "X_test_sequences = X_test_sequences.reshape((X_test_sequences.shape[0], X_test_sequences.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce34e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:26:27.494892: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define model inputs for categorical variables\n",
    "\n",
    "embedding_dim = 10  # Reduced embedding dimension\n",
    "\n",
    "input_item = Input(shape=(1,))\n",
    "embed_item = Embedding(input_dim=np.max(df['item_id_enc'])+1, output_dim=embedding_dim)(input_item)\n",
    "flat_item = Flatten()(embed_item)\n",
    "\n",
    "input_dept = Input(shape=(1,))\n",
    "embed_dept = Embedding(input_dim=np.max(df['dept_id_enc'])+1, output_dim=embedding_dim)(input_dept)\n",
    "flat_dept = Flatten()(embed_dept)\n",
    "\n",
    "input_store = Input(shape=(1,))\n",
    "embed_store = Embedding(input_dim=np.max(df['store_id_enc'])+1, output_dim=embedding_dim)(input_store)\n",
    "flat_store = Flatten()(embed_store)\n",
    "\n",
    "input_event = Input(shape=(1,))\n",
    "embed_event = Embedding(input_dim=np.max(df['event_name_1_enc'])+1, output_dim=embedding_dim)(input_event)\n",
    "flat_event = Flatten()(embed_event)\n",
    "\n",
    "input_evtype = Input(shape=(1,))\n",
    "embed_evtype = Embedding(input_dim=np.max(df['event_type_1_enc'])+1, output_dim=embedding_dim)(input_evtype)\n",
    "flat_evtype = Flatten()(embed_evtype)\n",
    "\n",
    "input_numerical = Input(shape=(5,))  # Adjust shape based on the number of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49191d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model input for the sales sequences\n",
    "input_sequences = Input(shape=(sequence_length, 1))\n",
    "\n",
    "# GRU layer for processing sequences\n",
    "lstm_out = LSTM(50)(input_sequences)  #\n",
    "\n",
    "# Concatenate GRU output with flattened embeddings\n",
    "concat = concatenate([flat_store, flat_dept, flat_item, flat_event, flat_evtype, flat_evtype, input_numerical])\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1)(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31711006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile model\n",
    "model = Model(inputs=[input_store, input_dept, input_item, input_event, input_evtype, input_sequences, input_numerical], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f199cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "72369/72369 [==============================] - 149s 2ms/step - loss: 181.8251 - val_loss: 1.9179\n",
      "Epoch 2/40\n",
      "72369/72369 [==============================] - 145s 2ms/step - loss: 1.9895 - val_loss: 1.8539\n",
      "Epoch 3/40\n",
      "72369/72369 [==============================] - 146s 2ms/step - loss: 1.9873 - val_loss: 1.9043\n",
      "Epoch 4/40\n",
      "72369/72369 [==============================] - 146s 2ms/step - loss: 1.9850 - val_loss: 1.8514\n",
      "Epoch 5/40\n",
      "72369/72369 [==============================] - 148s 2ms/step - loss: 1.9845 - val_loss: 1.8542\n",
      "Epoch 6/40\n",
      "55699/72369 [======================>.......] - ETA: 28s - loss: 1.9854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9830 - val_loss: 1.8517\n",
      "Epoch 9/40\n",
      "72369/72369 [==============================] - 149s 2ms/step - loss: 1.9820 - val_loss: 1.8880\n",
      "Epoch 10/40\n",
      "72369/72369 [==============================] - 145s 2ms/step - loss: 1.9845 - val_loss: 2.0120\n",
      "Epoch 11/40\n",
      "72369/72369 [==============================] - 148s 2ms/step - loss: 1.9815 - val_loss: 1.9610\n",
      "Epoch 12/40\n",
      "72369/72369 [==============================] - 150s 2ms/step - loss: 1.9815 - val_loss: 1.9622\n",
      "Epoch 13/40\n",
      "72369/72369 [==============================] - 149s 2ms/step - loss: 1.9834 - val_loss: 1.9840\n",
      "Epoch 14/40\n",
      "72369/72369 [==============================] - 149s 2ms/step - loss: 1.9850 - val_loss: 2.0117\n",
      "Epoch 15/40\n",
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9852 - val_loss: 1.8676\n",
      "Epoch 16/40\n",
      "72369/72369 [==============================] - 146s 2ms/step - loss: 1.9838 - val_loss: 2.1455\n",
      "Epoch 17/40\n",
      "34046/72369 [=============>................] - ETA: 1:06 - loss: 1.9879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72369/72369 [==============================] - 150s 2ms/step - loss: 1.9835 - val_loss: 1.8567\n",
      "Epoch 21/40\n",
      "47288/72369 [==================>...........] - ETA: 44s - loss: 1.9812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9803 - val_loss: 2.4685\n",
      "Epoch 25/40\n",
      "72369/72369 [==============================] - 149s 2ms/step - loss: 1.9861 - val_loss: 1.9300\n",
      "Epoch 26/40\n",
      "72369/72369 [==============================] - 152s 2ms/step - loss: 1.9815 - val_loss: 1.8742\n",
      "Epoch 27/40\n",
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9823 - val_loss: 1.8611\n",
      "Epoch 28/40\n",
      "72369/72369 [==============================] - 146s 2ms/step - loss: 1.9861 - val_loss: 1.8494\n",
      "Epoch 29/40\n",
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9852 - val_loss: 2.1572\n",
      "Epoch 30/40\n",
      "72369/72369 [==============================] - 145s 2ms/step - loss: 1.9828 - val_loss: 2.0798\n",
      "Epoch 31/40\n",
      "72369/72369 [==============================] - 152s 2ms/step - loss: 1.9853 - val_loss: 1.9978\n",
      "Epoch 32/40\n",
      "72369/72369 [==============================] - 148s 2ms/step - loss: 1.9837 - val_loss: 1.8529\n",
      "Epoch 33/40\n",
      "72369/72369 [==============================] - 148s 2ms/step - loss: 1.9823 - val_loss: 2.2660\n",
      "Epoch 34/40\n",
      "72369/72369 [==============================] - 145s 2ms/step - loss: 1.9842 - val_loss: 2.3381\n",
      "Epoch 35/40\n",
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9807 - val_loss: 2.0796\n",
      "Epoch 36/40\n",
      "72369/72369 [==============================] - 144s 2ms/step - loss: 1.9830 - val_loss: 2.2492\n",
      "Epoch 37/40\n",
      "72369/72369 [==============================] - 147s 2ms/step - loss: 1.9781 - val_loss: 2.2284\n",
      "Epoch 38/40\n",
      "72369/72369 [==============================] - 148s 2ms/step - loss: 1.9835 - val_loss: 2.2787\n",
      "Epoch 39/40\n",
      "72369/72369 [==============================] - 142s 2ms/step - loss: 1.9837 - val_loss: 1.8679\n",
      "Epoch 40/40\n",
      "72369/72369 [==============================] - 146s 2ms/step - loss: 1.9823 - val_loss: 1.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b1acf49b850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train_categorical[:, 0], X_train_categorical[:, 1], X_train_categorical[:, 2], X_train_categorical[:, 3], X_train_categorical[:, 4], X_train_sequences, X_train_numerical],\n",
    "    y_train,\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a237c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45231/45231 [==============================] - 53s 1ms/step\n",
      "Mean Squared Error (MSE): 1.8446230595788107\n",
      "Root Mean Squared Error (RMSE): 1.3581690099464097\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict([X_test_categorical[:, 0], X_test_categorical[:, 1], X_test_categorical[:, 2], X_test_categorical[:, 3], X_test_categorical[:, 4], X_test_sequences, X_test_numerical])\n",
    "\n",
    "# Evaluate the model performance\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "636c4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.8175005627942337\n",
      "R-squared (R²): 0.3129957418386349\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7172db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583147c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90206045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40e091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
